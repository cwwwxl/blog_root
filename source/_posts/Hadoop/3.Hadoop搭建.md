---
title: 3.Hadoop搭建教程
cover: 'https://s2.loli.net/2023/03/24/c6JCiWt3Yo1lqdF.jpg'
tags: Hadoop
categories: Hadoop
top_img: 'https://s2.loli.net/2023/03/24/c6JCiWt3Yo1lqdF.jpg'
abbrlink: '51741172'
---
### 1. Hadoop基础环境搭建（3台机械同时配置）

##### 1.1主机名解析

为了方便集群节点间的直接调用，在这个配置一下主机名解析，企业中推荐使用内部DNS服务器

```powershell
# 主机名成解析 编辑三台服务器的vi /etc/hosts文件，添加下面内容
192.168.90.100 master
192.168.90.106 node1
192.168.90.107 node2
#验证是否成功，可以ping通就代表配置成功
ping master
ping node1
ping node2

#修改centos系统的主机名,设置完成之后需要重启
hostnamectl set-hostname master
hostnamectl set-hostname node1
hostnamectl set-hostname node2
```

##### 1.2 时间同步

要求集群中的节点时间必须精确，这里使用chronyd服务从网络同步时间

企业中建议配置内部的会见同步服务器

```powershell
# 启动chronyd服务
[root@master ~]# systemctl start chronyd
[root@master ~]# systemctl enable chronyd
#使用date查看时间是否一致
[root@master ~]# date
```

##### 1.3  禁用iptable和firewalld服务

在运行的中会产生大量的iptables规则，为了不让系统规则跟它们混淆，直接关闭系统的规则

```powershell
# 1 关闭firewalld服务
[root@master ~]# systemctl stop firewalld
[root@master ~]# systemctl disable firewalld
# 2 关闭iptables服务
[root@master ~]# systemctl stop iptables
[root@master ~]# systemctl disable iptables
```

##### 1.4 禁用selinux

selinux是linux系统下的一个安全服务，如果不关闭它，在安装集群中会产生各种各样的奇葩问题

```powershell
# 编辑 vi /etc/selinux/config 文件，修改SELINUX的值为disable
# 注意修改完毕之后需要重启linux服务
SELINUX=disabled
```

##### 1.5 禁用swap分区

swap分区指的是虚拟内存分区，它的作用是物理内存使用完，之后将磁盘空间虚拟成内存来使用，启用swap设备会对系统的性能产生非常负面的影响，因此kubernetes要求每个节点都要禁用swap设备，但是如果因为某些原因确实不能关闭swap分区，就需要在集群安装过程中通过明确的参数进行配置说明

```powershell
# 编辑分区配置文件vi /etc/fstab，注释掉swap分区一行
# 注意修改完毕之后需要重启linux服务
vim /etc/fstab
注释掉 /dev/mapper/centos-swap swap
# /dev/mapper/centos-swap swap
```

##### 1.6 关闭防火墙

```shell
# 防火墙关闭
firewall-cmd --state	#查看防火墙状态
systemctl stop firewalld.service  #停止firewalld服务
systemctl disable firewalld.service  #开机禁用firewalld服务
```

##### 1.7 ssh免密登录

```shell
# ssh免密登录（只需要配置master至node1、node2、node3即可）

	#master生成公钥私钥 (一路回车)
	ssh-keygen  
	
	#master配置免密登录到node1 node2 
	ssh-copy-id master
	ssh-copy-id node1
	ssh-copy-id node2

	#测试是否免密成功，如果可以进去代表免密登录
	ssh master
	ssh node1
	ssh node2
```

##### 1.8 新建工作空间

```shell
#这个工作空间必须创建
mkdir -p /export/server/
mkdir -p /export/data/
mkdir -p /export/text/
```

##### 1.9 Java环境变量

```shell
# JDK 1.8安装  上传 jdk-8u241-linux-x64.tar.gz到/export/server/目录下
cd /export/server/
tar -zxvf jdk-8u241-linux-x64.tar.gz
#解压完成之后进行重命名，在/export/server/这个路径下使用命令
mv jdk-1.1.0 jdk

	#配置环境变量
	vim /etc/profile
	
	export JAVA_HOME=/export/server/jdk
	export PATH=$PATH:$JAVA_HOME/bin
	export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar
	
	#重新加载环境变量文件
	source /etc/profile
	#验证jdk 是否安装成功
	java -version

```

### 2.部署（3台机械同时配置）

##### 1.1上传Hadoop安装包到master /export/server

```shell
hadoop-3.3.0-Centos7-64-with-snappy.tar.gz

tar -zxvf hadoop-3.3.0-Centos7-64-with-snappy.tar.gz
```

##### 1.2修改配置文件(cd /export/server/hadoop-3.3.0/etc/hadoop)

- hadoop-env.sh


```shell
#文件最后添加
export JAVA_HOME=/export/server/jdk
export HDFS_NAMENODE_USER=root
export HDFS_DATANODE_USER=root
export HDFS_SECONDARYNAMENODE_USER=root
export YARN_RESOURCEMANAGER_USER=root
export YARN_NODEMANAGER_USER=root 
```

- ​	core-site.xml

	```xml
	<!-- 设置默认使用的文件系统 Hadoop支持file、HDFS、GFS、ali|Amazon云等文件系统 -->
	<property>
	    <name>fs.defaultFS</name>
	    <value>hdfs://master:8020</value>
	</property>
	
	<!-- 设置Hadoop本地保存数据路径 -->
	<property>
	    <name>hadoop.tmp.dir</name>
	    <value>/export/data/hadoop-3.3.0</value>
	</property>
	
	<!-- 设置HDFS web UI用户身份 -->
	<property>
	    <name>hadoop.http.staticuser.user</name>
	    <value>root</value>
	</property>
	
	<!-- 整合hive 用户代理设置 -->
	<property>
	    <name>hadoop.proxyuser.root.hosts</name>
	    <value>*</value>
	</property>
	
	<property>
	    <name>hadoop.proxyuser.root.groups</name>
	    <value>*</value>
	</property>
	
	<!-- 文件系统垃圾桶保存时间 -->
	<property>
	    <name>fs.trash.interval</name>
	    <value>1440</value>
	</property>
	```

- hdfs-site.xml

	```xml
	<!-- 设置SNN进程运行机器位置信息 -->
	<property>
	    <name>dfs.namenode.secondary.http-address</name>
	    <value>node2:9868</value>
	</property>
	```

- mapred-site.xml

	```xml
	<!-- 设置MR程序默认运行模式： yarn集群模式 local本地模式 -->
	<property>
	  <name>mapreduce.framework.name</name>
	  <value>yarn</value>
	</property>
	
	<!-- MR程序历史服务地址 -->
	<property>
	  <name>mapreduce.jobhistory.address</name>
	  <value>master:10020</value>
	</property>
	 
	<!-- MR程序历史服务器web端地址 -->
	<property>
	  <name>mapreduce.jobhistory.webapp.address</name>
	  <value>master:19888</value>
	</property>
	
	<property>
	  <name>yarn.app.mapreduce.am.env</name>
	  <value>HADOOP_MAPRED_HOME=${HADOOP_HOME}</value>
	</property>
	
	<property>
	  <name>mapreduce.map.env</name>
	  <value>HADOOP_MAPRED_HOME=${HADOOP_HOME}</value>
	</property>
	
	<property>
	  <name>mapreduce.reduce.env</name>
	  <value>HADOOP_MAPRED_HOME=${HADOOP_HOME}</value>
	</property>
	```

- yarn-site.xml

	```xml
	<!-- 设置YARN集群主角色运行机器位置 -->
	<property>
		<name>yarn.resourcemanager.hostname</name>
		<value>master</value>
	</property>
	<property>
	    <name>yarn.nodemanager.aux-services</name>
	    <value>mapreduce_shuffle</value>
	</property>
	
	<!-- 是否将对容器实施物理内存限制 -->
	<property>
	    <name>yarn.nodemanager.pmem-check-enabled</name>
	    <value>false</value>
	</property>
	
	<!-- 是否将对容器实施虚拟内存限制。 -->
	<property>
	    <name>yarn.nodemanager.vmem-check-enabled</name>
	    <value>false</value>
	</property>
	
	<!-- 开启日志聚集 -->
	<property>
	  <name>yarn.log-aggregation-enable</name>
	  <value>true</value>
	</property>
	
	<!-- 设置yarn历史服务器地址 -->
	<property>
	    <name>yarn.log.server.url</name>
	    <value>http://master:19888/jobhistory/logs</value>
	</property>
	
	<!-- 历史日志保存的时间 7天 -->
	<property>
	  <name>yarn.log-aggregation.retain-seconds</name>
	  <value>604800</value>
	</property>
	```



- 使用vim 修改 workers文件

	```shell
	master
	node1
	node2

	```


- 将hadoop添加到环境变量（3台机器）

	```shell
	#配置环境变量
	vim /etc/profile
	
	export HADOOP_HOME=/export/server/hadoop-3.3.0
	export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin
	
	#重新加载环境变量文件
	source /etc/profile
	#验证是否成功
	hadoop -version
	
	
	```

- ##### Hadoop集群启动（只在master节点）

	- （==首次启动==）格式化namenode

		```shell
		hdfs namenode -format
		```

	- 脚本一键启动

		```shell
		[root@master ~]# start-dfs.sh 
		Starting namenodes on [node1]
		Last login: Thu Nov  5 10:44:10 CST 2020 on pts/0
		Starting datanodes
		Last login: Thu Nov  5 10:45:02 CST 2020 on pts/0
		Starting secondary namenodes [node2]
		Last login: Thu Nov  5 10:45:04 CST 2020 on pts/0
		
		[root@master ~]# start-yarn.sh 
		Starting resourcemanager
		Last login: Thu Nov  5 10:45:08 CST 2020 on pts/0
		Starting nodemanagers
		Last login: Thu Nov  5 10:45:44 CST 2020 on pts/0
		```

	- Web  UI页面
		- HDFS集群：http://192.168.90.100:9870/  
		- YARN集群：http://192.168.90.100:8088/
		- HDFS集群：http://master:9870/  
		- YARN集群：http://master:8088/

```shell
[root@master hadoop]# start-dfs.sh
Starting namenodes on [node1]
上一次登录：二 12月 27 11:19:23 CST 2022从 192.168.169.1pts/0 上
Starting datanodes
上一次登录：二 12月 27 11:20:33 CST 2022pts/0 上
Starting secondary namenodes [node2]
上一次登录：二 12月 27 11:20:35 CST 2022pts/0 上

[root@master hadoop]# jps
1793 NameNode
1921 DataNode
2218 Jps
[root@master hadoop]# start-yarn.sh
Starting resourcemanager
上一次登录：二 12月 27 11:20:43 CST 2022pts/0 上
Starting nodemanagers
上一次登录：二 12月 27 11:24:29 CST 2022pts/0 上
[root@master hadoop]#


```


